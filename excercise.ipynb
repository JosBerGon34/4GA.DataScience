{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np, random\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#BIBLIOGRAFIA: https://www.geeksforgeeks.org/multinomial-naive-bayes/\n",
    "#https://www.geeksforgeeks.org/bernoulli-naive-bayes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   package_name  891 non-null    object\n",
      " 1   review        891 non-null    object\n",
      " 2   polarity      891 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_textoraw = pd.read_csv(\"/workspaces/NaiveBayesJBG/playstore_reviews.csv\")\n",
    "#df_textoraw = df_textoraw.drop(['package_name'],inplace=True, axis=1)\n",
    "df_textoraw.info()\n",
    "#df_textoraw.to_csv(\"/workspaces/NaiveBayesJBG/playstore_reviews.csv\", axis=1, index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      privacy at least put some option appear offlin...\n",
       "1      messenger issues ever since the last update, i...\n",
       "2      profile any time my wife or anybody has more t...\n",
       "3      the new features suck for those of us who don'...\n",
       "4      forced reload on uploading pic on replying com...\n",
       "                             ...                        \n",
       "886    loved it i loooooooooooooovvved it because it ...\n",
       "887    all time legendary game the birthday party lev...\n",
       "888    ads are way to heavy listen to the bad reviews...\n",
       "889    fun works perfectly well. ads aren't as annoyi...\n",
       "890    they're everywhere i see angry birds everywher...\n",
       "Name: review, Length: 891, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textolist = ()\n",
    "df_textoraw[\"review\"] = df_textoraw[\"review\"].str.strip().str.lower()\n",
    "df_textoraw[\"review\"].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_textoraw[\"review\"], df_textoraw[\"polarity\"], test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = CountVectorizer(stop_words = \"english\")\n",
    "x_train_vect = vec_model.fit_transform(x_train).toarray()\n",
    "x_test_vect = vec_model.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709    love/hate has bug and security issues. i tried...\n",
       "439    whatsapp i use this app now that blackberry me...\n",
       "840                             usefully verry  nice app\n",
       "720    fonts why in the heck is this thing analysing ...\n",
       "39     app doesn't work after latest upgrade the face...\n",
       "                             ...                        \n",
       "433    app continuously losses connection, at times i...\n",
       "773    way below expection. why does it lag so much? ...\n",
       "25     can't install (error code: -505) have samsung ...\n",
       "84     sort it out why can i not get my networks post...\n",
       "10     what the heck?! can't get status updates to be...\n",
       "Name: review, Length: 179, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       126\n",
      "           1       0.70      0.40      0.51        53\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.74      0.66      0.68       179\n",
      "weighted avg       0.76      0.77      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Entreno multinominal.\n",
    "mnb = MultinomialNB(alpha=0.8, fit_prior=True, force_alpha=True)\n",
    "mnb.fit(x_train_vect, y_train)\n",
    "y_train_pred = mnb.predict(x_train_vect)\n",
    "#Muestro tabla de scores:\n",
    "print(classification_report(y_test,y_pred))\n",
    "#Guardamos modelo.\n",
    "with open('Models/mnb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mnb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       126\n",
      "           1       0.70      0.40      0.51        53\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.74      0.66      0.68       179\n",
      "weighted avg       0.76      0.77      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Entreno gaussian.\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_vect, y_train)\n",
    "y_train_pred = gnb.predict(x_train_vect)\n",
    "#Tabla de scores\n",
    "print(classification_report(y_test,y_pred))\n",
    "#Guardo modelo.\n",
    "with open('Models/gnb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gnb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       126\n",
      "           1       0.70      0.40      0.51        53\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.74      0.66      0.68       179\n",
      "weighted avg       0.76      0.77      0.75       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Entreno Bernoulli\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_vect, y_train)\n",
    "y_pred = bnb.predict(X_test_vect)\n",
    "#Muestro la tabla de scores.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Guardo mi model en la carpeta Models\n",
    "with open('Models/bnb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bnb, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
