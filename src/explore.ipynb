{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import joblib\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "random.seed(42),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA\n",
    "PASO1) OBTENCION Y LIMPIEZA DE DATOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rd= pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/decision-tree-project-tutorial/main/diabetes.csv')\n",
    "df_rd.to_csv(\"../data/raw/df_rd.csv\", index=False)\n",
    "df_rd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1) FILTRADO DE NANS Y NULLS.\n",
    "df_rd = df_rd.drop_duplicates().reset_index(drop = True)\n",
    "df_rd = df_rd.fillna(0)\n",
    "df_rd.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2) IDENTIFICACION TARGET Y ETIQUETACION DE PREDICTORAS.\n",
    "#NUESTRO TARGET ES OUTCOME, VARIABLE QUE NOS INDICA CON 0 QUE NO TIENE DIABETES, Y UNO QUE SI TIENE.\n",
    "#EL OBJETIVO ES REALIZAR UN MODELO QUE PREDIGA DADO UNOS DATOS SI EL PACIENTE TIENE DIABETES.\n",
    "def vartype(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    df_tipos = pd.DataFrame({'Tipo': ['Numérica']*len(num_cols) + ['Categórica']*len(cat_cols),\n",
    "                            'Columna': num_cols + cat_cols})\n",
    "    total_num = len(num_cols)\n",
    "    total_cat = len(cat_cols)\n",
    "    total_general = total_num + total_cat\n",
    "    # Crear una lista de diccionarios para las nuevas filas\n",
    "    new_rows = [{'Tipo': 'Total Numérico', 'Columna': total_num},\n",
    "                {'Tipo': 'Total Categórico', 'Columna': total_cat},\n",
    "                {'Tipo': 'Total General', 'Columna': total_general},]\n",
    "    df_tipos = pd.concat([df_tipos, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    return df_tipos\n",
    "df_rd_vars= vartype(df_rd)\n",
    "print(df_rd_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3) SIMPLIFICACION DEL DATAFRAME.\n",
    "#NOS SERVIREMOS DE LA FUNCIONALIDAD SELECTKBEST PARA SIMPLIFICAR EL DATAFRAME, SE SIRVE DE CRITERIOS MATEMATICOS PARA ESCOGER LAS PREDICTORAS.\n",
    "#AL NO HABER CATEGORICAS NO USAREMOS EL MODO CHI2, SOLO EL F_reg.\n",
    "#DE ENTRADA INTENTAREMOS REDUCIR EL NUMERO DE PREDICTORAS DE 8 A 6.\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "# Suponiendo que 'df_rd' es tu DataFrame y 'target' es la columna objetivo\n",
    "X = df_rd.drop('Outcome', axis=1)  # Características\n",
    "y = df_rd['Outcome']  # Variable objetivo\n",
    "# Seleccionar las 6 mejores características (ajusta el valor de k según tus necesidades)\n",
    "selector = SelectKBest(f_regression, k=6)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "# Obtener las características seleccionadas\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "# Crear un nuevo DataFrame con las características seleccionadas y la variable objetivo\n",
    "df_Eda = pd.DataFrame(X_new, columns=selected_features)\n",
    "df_Edav7 = pd.concat([df_Eda, y], axis=1)  #Agregamos manualmente la target y al dataframe para completarlo.\n",
    "df_Edav7.to_csv('../data/processed/df_edav7.csv', index=False)\n",
    "# Visualizar las primeras filas del DataFrame\n",
    "print(df_Edav7.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataframe resultante es tal y como queriamos, 6 predictoras y nuestra 'Outcome' como var target, total 7 vars.(df_Edav7, df_Eda(es el dataframe procesado de df_rd(dataframe_RawData)) con 7 variables(v7))\n",
    "Podemos echar un vistazo al heatmap para ver correlaciones, y usando criterio de correlacion simplificarlo aun mas.(No hay necesidad de hacerlo en este caso, ya hay pocas variables.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4)FILTRADO DF: Bifurcacion dataframe con outliers(col), y sin outliers(sol), guardando datos atipicos en diccionarios por variable(fmt Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe sin outliers.\n",
    "df_E7_sol= df_Edav7.copy()\n",
    "df_E7_sol.to_csv('../data/processed/df_E7_sol.csv', index=False)\n",
    "#dataframe con outliers.\n",
    "df_E7_col= df_Edav7.copy()\n",
    "df_E7_col.to_csv('../data/processed/df_E7_col.csv', index=False)\n",
    "\n",
    "#3.2) guardar outliers en la carpeta lims\n",
    "def LimsOlSaveJson(df, columns, output_path, lower_limit_zero=True):\n",
    "    for column in columns:\n",
    "        stats = df[column].describe()\n",
    "        iqr = stats['75%'] - stats['25%']\n",
    "        ul = stats['75%'] + (2 * iqr)\n",
    "        ll = max(stats['25%'] - (2 * iqr), 0 if lower_limit_zero else None)\n",
    "        limits = {\"upper_limit\": ul, \"lower_limit\": ll}\n",
    "\n",
    "        # Traducir signos especiales que dan error a la hora de guardar\n",
    "        safe_column_name = column.replace(' ', '_').replace('/', '_').replace('%', '_')\n",
    "\n",
    "        file_path = f\"{output_path}/limits_{safe_column_name}.json\"\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(limits, f, indent=4)\n",
    "\n",
    "        df[column] = df[column].apply(lambda x: ul if x > ul else ll if x < ll else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "num_vars = df_E7_sol.select_dtypes(include=np.number).columns.tolist()\n",
    "LimsOlSaveJson(df_E7_sol, num_vars, '../data/processed/lims')\n",
    "df_E7_sol.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos con el dataframe sin outliers, alguno pensara que siendo personas no se deberia hacer, pero hay valores biologicos surrealistas como valores atipicos,\n",
    "mejor entrenar un modelo que se ajuste a la gran mayoria de personas.\n",
    "Tamnbien he decidio trabajar con datos originales sin Normalizar/estandarizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 2) ANÁLISIS UNIVARIABLE NUMERICA.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "def GrafUniNum(df_no_outliers, df_with_outliers, hist_vars, box_vars):\n",
    "  \"\"\"\n",
    "  Creamos un conjunto de graficos, los histogramas sin outliers para presenciar mejor la distribucion,\n",
    "  los graficos de caja con outliers para visualizarlos.\n",
    "  Args:\n",
    "      df_no_outliers\n",
    "      df_with_outliers\n",
    "      hist_vars: lista de nombres de columnas.\n",
    "      box_vars: lista de nombres de columnas.\n",
    "  \"\"\"\n",
    "\n",
    "  num_hist_vars = len(hist_vars)  #Determinamos el numero de variables para el histograma sin Ol's\n",
    "  num_box_vars = len(box_vars)  #Determinamos el numero de variables para los graficos de caja con Ol's\n",
    "  total_vars = num_hist_vars + num_box_vars\n",
    "\n",
    "  #Determinamos la cuadricula de graficos optima, evitando el zero\n",
    "  if total_vars <= 4:\n",
    "    row, col = 2, 2  \n",
    "  elif total_vars <= 6:\n",
    "    row, col = 2, 3  \n",
    "  else:\n",
    "    # Usaremos una rejilla de graficos variable en caso de exceder los casos anteriores.\n",
    "    row = math.ceil(total_vars / 3)\n",
    "    col = 3\n",
    "  fig, axs = plt.subplots(row, col, figsize=(20, 5 * row))\n",
    "  i = 0\n",
    "  for var in hist_vars:\n",
    "    row_index = i // col\n",
    "    col_index = i % col\n",
    "    sns.histplot(ax=axs[row_index, col_index], data=df_no_outliers, x=var, color=\"blue\")\n",
    "    max_val_no_outliers = df_no_outliers[var].max()\n",
    "    axs[row_index, col_index].set_xlim(0, max_val_no_outliers)\n",
    "    axs[row_index, col_index].set_xticklabels(axs[row_index, col_index].get_xticklabels(), rotation=90)\n",
    "    i += 1\n",
    "  for var in box_vars:\n",
    "    row_index = i // col\n",
    "    col_index = i % col\n",
    "    sns.boxplot(ax=axs[row_index, col_index], data=df_with_outliers, x=var, color=\"red\")\n",
    "    axs[row_index, col_index].set_xticklabels(axs[row_index, col_index].get_xticklabels(), rotation=90)\n",
    "    i += 1\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "#Preparamos la llamada a la funcion y el input\n",
    "hist_vars = df_E7_sol.columns\n",
    "box_vars = df_E7_col.columns\n",
    "GrafUniNum(df_E7_sol, df_E7_col, hist_vars, box_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos varias distribuciones predominantes, como es obvio en variables como pregnancies o insulina, donde normalmente se tienen pocos hijos o se tienen valores  relativamente bajos de insulina cuando estas sano, se observa una distribucion normal asimetrica,\n",
    "desplazada a valores cerca del 0. Es decir el mayor porcentaje de muestras se ubican cuando el rango de estas dos variables se aproxima a 0.\n",
    "El mismo caso pasa con Age, pero empieza esa distribucion cuando el valor del rango age vale 20, entendemos que es porque hasta que las muestras no tienen esa edad, no figuran registrados.\n",
    "BMi y pedigree diabetes function tienen una distribucion casi simetrica en el centro del rango de valor de estas dos variables.\n",
    "En cuanto a los outliers, es un data set bastante limpio donde hay pocas muestras fuera de los rangos cuartilicos y alejados del maximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 4) ANÁLISIS MULTIVARIABLE NUMERICO-NUMERICO.\n",
    "print('Multivariable sin outliers df valores reales')\n",
    "sns.pairplot(df_E7_sol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 4)MAPA DE CORRELACIÓN. MAPA DE CALOR.\n",
    "\n",
    "target_var = \"Outcome\"  \n",
    "df_heatmap = df_E7_sol.reindex(columns=[target_var] + list(df_E7_sol.columns.difference([target_var])))\n",
    "#Ahora representamos el grafico.\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(df_heatmap.corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMO PODEMOS OBSERVAR EL SELECTKBEST PARA REALIZAR EL EDA AJUSTADO FUNCIONA DE MARAVILLA. PODRIAMOS HACER ALGO CON LAS COLUMNAS PREGNANCIES Y AGE PERO YA TENEMOS UN NUMERO BAJO DE VARIABLES.\n",
    "Poco mas que añadir, observamos correlaciones leves y alguna bastante significativa como Age y pregnancies(0.55).\n",
    "Con respecto a la variable TARGET hay algunas con coeficientes superiores al 0.20 y solo dos con correlacion negativa, muy leves por cierto.\n",
    "Creo que con estos datos se podra hacer un modelo de arbol de decision bastante bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 5) FEATURE ENGINEERING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5) FUNCION SPLIT TRAIN/TEST:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def split_and_save_data(df, target_column, output_dir, test_size=0.20, random_state=42, filename_prefix=\"\"):\n",
    "  X = df.drop(columns=target_column)\n",
    "  y = df[target_column]\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "  train_dir = os.path.join(output_dir, \"train\")\n",
    "  test_dir = os.path.join(output_dir, \"test\")\n",
    "  os.makedirs(train_dir, exist_ok=True)\n",
    "  os.makedirs(test_dir, exist_ok=True)\n",
    "  X_train.to_csv(os.path.join(train_dir, f\"{filename_prefix}_X_train.csv\"), index=False)\n",
    "  X_test.to_csv(os.path.join(test_dir, f\"{filename_prefix}_X_test.csv\"), index=False)\n",
    "  y_train.to_csv(os.path.join(train_dir, f\"{filename_prefix}_y_train.csv\"), index=False)\n",
    "  y_test.to_csv(os.path.join(test_dir, f\"{filename_prefix}_y_test.csv\"), index=False)\n",
    "output_dir = '../data/processed/Split'\n",
    "target_column = 'Outcome'\n",
    "split_and_save_data(df_E7_sol, target_column, output_dir, filename_prefix=\"rawsol\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5) FEATURE ENGINEERING, DECISION TREE:\n",
    "#PREPARACION DE DATOS\n",
    "#Dataframes para representacion de graficos(Incluyendo la var target de nuevo como columna del df con X train/test).\n",
    "X_train = pd.read_csv('../data/processed/Split/train/rawsol_X_train.csv', index_col=False).copy()\n",
    "y_train = pd.read_csv('../data/processed/Split/train/rawsol_y_train.csv', index_col=False).copy()\n",
    "X_test = pd.read_csv('../data/processed/Split/test/rawsol_X_test.csv', index_col=False).copy()\n",
    "y_test = pd.read_csv('../data/processed/Split/test/rawsol_y_test.csv', index_col=False).copy()\n",
    "#DF's\n",
    "df_X_train = pd.DataFrame(X_train.copy(), columns=['Pregnancies','Glucose', 'Insulin',\t'BMI', 'DiabetesPedigreeFunction','Age'])\n",
    "df_X_test = pd.DataFrame(X_test.copy(), columns=['Pregnancies','Glucose', 'Insulin',\t'BMI', 'DiabetesPedigreeFunction','Age'])\n",
    "df_X_train['Outcome'] = y_train.copy()\n",
    "df_X_test[\"Outcome\"]= y_test.copy()\n",
    "\n",
    "#Arrays para el calculo sin formatos, indices o indices de columnas\n",
    "a_X_train = pd.read_csv('../data/processed/Split/train/rawsol_X_train.csv', index_col=False).copy().values\n",
    "a_y_train = pd.read_csv('../data/processed/Split/train/rawsol_y_train.csv', index_col=False).copy().values\n",
    "a_X_test = pd.read_csv('../data/processed/Split/test/rawsol_X_test.csv', index_col=False).copy().values\n",
    "a_y_test = pd.read_csv('../data/processed/Split/test/rawsol_y_test.csv', index_col=False).copy().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 5) Representacion grafico lineas paralelas.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = (\"#fd2e02\",\"#8a493b\",\"#fa9904\",\"#9d7639\",\"#ffd800\",\"#ac9b3b\",\"#b0fb03\",\"#7e9942\",\"#57fe04\",\"#5d9b3e\",\"#03fb25\",\"#399c47\",\"#03fee3\",\"#349c91\",\"#029dfb\",\"#3f7ea4\",\"#3f7ea4\",\"#395d9b\",\"#4b05f9\",\"#543d8e\",\"#8700ff\",\"#683892\",\"#f300ff\",\"#863f89\",\"#fb048b\",\"#893f68\")\n",
    "linewidth = 1\n",
    "pd.plotting.parallel_coordinates(df_E7_col, \"Outcome\", color=colors, linewidth=linewidth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5) MODELO ARBOL DE DECISION.\n",
    "#Este modelo trabaja categorizando la informacion, ademas de que has de presentar los segmentos de TRAIN/TEST en formato dataframe,\n",
    "#Hay que tener cuidado a la hora de introducir los inputs.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(df_X_train.copy().drop(['Outcome'],axis=1), df_X_train['Outcome'].copy())\n",
    "y_test = df_X_test['Outcome'].copy()\n",
    "#Vamos a diseñar un modelo de arbol sencillo para nuestra variable target, en su parametrizacion, class_name(etiquetado categorico y resolucion de la prediccion de una hoja o decision de pasar al siguiente nodo)\n",
    "#Si el arbol concluye class name = 0, querra decir que la muestra predecida no tiene diabetes y por lo tanto el arbol termina en esa Hoja \"leaf\"\n",
    "#si el arbol concluye class name = 1, querra decir que la muestra predecida si tiene diabetes y por lo tanto el arbol termina en esa Hoja \"leaf\"\n",
    "#si el arbol concluye class name = 2, querra decir que la muestra predecida aun se desconoce su clase en su variable predict y \"Outcome\" por lo tanto el arbol ir'a al siguiente Nodo y bajara un nivel.\n",
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "tree.plot_tree(model, feature_names = list(df_X_train.columns.copy()), class_names = [\"0\", \"1\", \"2\"], filled = True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las observaciones necesarias para sacar un acuracy score respecto a los datos entrenados y los predecidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASO 5) ACURACY SCORE.\n",
    "y_pred = model.predict(df_X_test.drop(['Outcome'].copy(), axis=1))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(a_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASO 5.1) OPTIMIZACION MODELO , AJUSTE HIPERPARAMETROS via GRIDSEARCH, RANDOMSEARCH y Libreria HiperOPT.\n",
    "A partir de este momento, toda la mejora se haran con copias del modelo base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1.1)OPTIMIZACION HIPERPARAMETROS VIA GRIDSEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "hyperparams = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"], #Criterio de División: Determina la calidad de una división. \n",
    "                                      #- gini: Impureza de Gini mide la probabilidad de clasificar \n",
    "                                      #erróneamente un punto de datos si fuera elegido al azar del nodo actual.\n",
    "                                      #- entropy: Ganancia de información mide la reducción \n",
    "                                      # en la incertidumbre después de una división.\n",
    "                                      \n",
    "    \"max_depth\": [None, 6, 36, 216],   #Profundidad Máxima: Controla la profundidad máxima del árbol.\n",
    "                                      #Un árbol más profundo puede capturar patrones más complejos pero es propenso al sobreajuste.\n",
    "                                     \n",
    "    \"min_samples_split\": [3, 9, 27],  #Muestras Mínimas para Dividir: Especifica el número mínimo de muestras \n",
    "                                      #requeridas para dividir un nodo interno. Un valor más alto puede prevenir el sobreajuste.\n",
    "                                    \n",
    "    \"min_samples_leaf\": [3, 6, 9]     #Muestras Mínimas por Hoja: Establece el número mínimo de muestras requeridas \n",
    "                                      #para estar en una hoja. Un valor más alto puede prevenir el sobreajuste y hacer que el árbol sea más robusto.\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model, hyperparams, scoring = \"accuracy\", cv = 9)\n",
    "grid \n",
    "\n",
    "#Parámetros clave en GridSearchCV:\n",
    "#MODEL:\n",
    "#Seleccionamos el modelo que queremos mejorar\n",
    "#En este caso, un DecisionTreeClassifier.\n",
    "#PARAM_GRID(hyperparams):\n",
    "#Este diccionario especifica los diferentes valores que ajustamos para cada hiperparámetro.\n",
    "#Probamos diferentes combinaciones de criterion, max_depth, min_samples_split, y min_samples_leaf.\n",
    "#SCORING:\n",
    "#Este parámetro define la métrica de evaluación que se utiliza para comparar diferentes combinaciones de hiperparámetros.\n",
    "#En este caso, se utiliza la \"accuracy\" (precisión) para evaluar el rendimiento del modelo.\n",
    "#CV:\n",
    "#Este parámetro especifica el número de pliegues de validación cruzada que utilizamos para evaluar el modelo.\n",
    "#En este caso, se utiliza una validación cruzada de 10 pliegues, lo que significa que los datos se dividen en 10 partes,\n",
    "#se entrenan modelos en 9 partes y se evalúan en la parte restante, y esto se repite 10 veces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "grid.fit(X_train.copy(), y_train.copy())\n",
    "print(f\"Mejor combo de hiperparametros: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora ajustamos nuestro modelo decision tree con los parametros ajustados obtenidos por gridsearch\n",
    "model = DecisionTreeClassifier(criterion = \"gini\", max_depth = None, min_samples_leaf = 9, min_samples_split = 27, random_state = 42)\n",
    "model.fit(X_train.copy(), y_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos el test\n",
    "y_pred2= model.predict(X_test.copy())\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from pickle import dump\n",
    "accuracy = accuracy_score(y_test.copy(), y_pred2)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAMOS RESULTADOS GRIDSEARCH.\n",
    "dump(model, open(\"../models/3c_G_MDn_MSL9_MSS27.sav\", \"wb\")) # model = DecisionTreeClassifier(criterion = \"gini\", max_depth = None, min_samples_leaf = 9, min_samples_split = 27, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEMOS TENIDO UNA GANANCIA POCO SIGNIFICATIVA ALREDEDOR DE UN +0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1.2)OPTIMIZACION HIPERPARAMETROS VIA RANDOMSEARCH, IMPORTANTE REALIZAR MEJORA CON COPIAS DE LAS VARIABLES SPLIT TRAIN/TEST PARA NO SOBREESCRIBIR Y NO ACUMULAR SOBREENTRENO\n",
    "#Solo se puede mejorar una vez desde que hicimos el decision tree default. es lo optimo.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "# Espacio de búsqueda de hiperparámetros\n",
    "param_dist = {\n",
    "    'max_depth': randint(0,6),\n",
    "    'max_features': randint(1, 9),\n",
    "    'min_samples_leaf': randint(1, 9),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Crear el objeto RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, cv=6, n_iter=9)\n",
    "# Ajustar el modelo\n",
    "random_search.fit(X_train.copy(), y_train.copy())\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = random_search.best_params_\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora ajustamos nuestro modelo decision tree con los parametros ajustados obtenidos por randomsearch\n",
    "model = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 5, max_features = 8, min_samples_leaf = 6,random_state = 42)\n",
    "model.fit(X_train.copy(), y_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediccion via RandomSearch\n",
    "y_pred3 = model.predict(X_test.copy())\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from pickle import dump\n",
    "accuracy = accuracy_score(y_test.copy(), y_pred3)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAMOS RESULTADOS. RANDOMSEARCH\n",
    "dump(model, open(\"../models/3c_E_MD5_MF8_MSF6.sav\", \"wb\")) # model = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 5, max_features = 8, min_samples_leaf = 6,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEMOS MEJORADO SIGNIFICATIVAMENTE NUESTRO MODELO SIN SOBREENTRENO, DADO QUE HEMOS USADO LOS DATOS BASE TRAS EL PRIMER MODELADO.\n",
    "DE 0.7142857142857143 EN DEFAULT A 0.7727272727272727 CON RANDOMSEARCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1.2)OPTIMIZACION HIPERPARAMETROS VIA LIBRERIA HIPEROPT\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def objective(space):\n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=space['max_depth'],\n",
    "        min_samples_split=int(space['min_samples_split']),  # valores enteros solo sin decs.\n",
    "        min_samples_leaf=int(space['min_samples_leaf']),  \n",
    "        criterion=space['criterion'],\n",
    "        max_features=int(space['max_features']),\n",
    "        #class_weight=space['class_weight'],\n",
    "        #ccp_alpha=space['ccp_alpha']\n",
    "    )\n",
    "    scores = cross_val_score(clf, X, y, cv=5) #EL cv lo podemos modificar tambien.\n",
    "    return -scores.mean()  # Maximize accuracy\n",
    "\n",
    "space = { #hay que indicar explicitamente instrucciones que hagan referencia a obtencion de valores enteros sin decimales.\n",
    "          #ya que los parametros del decision tree son enteros.\n",
    "    'max_depth': hp.choice('max_depth', range(1, 21)), #Indicamos el rango de max depth\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1), #Indicamos el rango de msp\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1), #Indicamos el rango de msf\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']), #Indicamos el rango categorico de criterion\n",
    "    'max_features': hp.quniform('max_features', 1, 9, 1), #Indicamos el rango de mf\n",
    "    #'class_weight': hp.choice('class_weight', [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 3}]), #esta la obviamos porque nuestra clase ya esta definida en el punto de partida\n",
    "    #'ccp_alpha': hp.uniform('ccp_alpha', 0.0, 0.1) #no queremos modificar el alpha, hace referencia al ajuste lineal de las variables, podemos modificarlo, pero habria que mirar que hace exactamente.\n",
    "}\n",
    "\n",
    "best = fmin(objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora ajustamos nuestro modelo decision tree con los parametros ajustados obtenidos por la libreria HyperOpt.\n",
    "model = DecisionTreeClassifier(criterion = \"gini\", max_depth = 45, max_features = 8, min_samples_leaf = 4, min_samples_split=7, random_state = 42)\n",
    "model.fit(X_train.copy(), y_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos la prediccion.\n",
    "y_pred4 = model.predict(X_test.copy())\n",
    "y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from pickle import dump\n",
    "accuracy = accuracy_score(y_test.copy(), y_pred4)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAMOS RESULTADOS. hyperopt\n",
    "dump(model, open(\"../models/3c_G_MD4_MF8_MSL4_MSS7.sav\", \"wb\")) #{'criterion': np.int64(0), 'max_depth': np.int64(4), 'max_features': np.float64(8.0), 'min_samples_leaf': np.float64(4.0), 'min_samples_split': np.float64(7.0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2) FEATURE ENGINEERING: RANDOM FOREST\n",
    "\n",
    "Podemos construir un árbol de decisión fácilmente en Python utilizando la librería scikit-learn y las funciones RandomForestClassifier y RandomForestRegressor. \n",
    "Algunos de sus hiperparámetros más importantes y los primeros en los que debemos centrarnos son:\n",
    "n_estimators: Este es probablemente el hiperparámetro más importante. Define el número de árboles de decisión en el bosque. En general, un número mayor de árboles aumenta la precisión y hace que las predicciones sean más estables, pero también puede ralentizar considerablemente el tiempo de cálculo.\n",
    "\n",
    "bootstrap: Este hiperparámetro se usa para controlar si se utilizan muestras de bootstrap (muestreo con reemplazo) para la construcción de árboles.\n",
    "\n",
    "max_depth: La profundidad máxima de los árboles. Esto es esencialmente cuántas divisiones puede hacer el árbol antes de hacer una predicción.\n",
    "\n",
    "min_samples_split: El número mínimo de muestras necesarias para dividir un nodo en cada árbol. Si se establece un valor alto, evita que el modelo aprenda relaciones demasiado específicas y, por tanto, ayuda a prevenir el sobreajuste.\n",
    "\n",
    "min_samples_leaf: El número mínimo de muestras que se deben tener en un nodo hoja en cada árbol.\n",
    "\n",
    "max_features: El número máximo de características a considerar al buscar la mejor división dentro de cada árbol. Por ejemplo, si tenemos 10 características, podemos elegir que cada árbol considere solo un subconjunto de ellas al decidir dónde dividir.\n",
    "\n",
    "Como podemos ver, solo los dos primeros hiperparámetros hacen referencia al random forest, mientras que el resto se relacionan con los árboles de decisión. Otro hiperparámetro muy importante es el random_state, que controla la semilla de generación aleatoria. Este atributo es crucial para asegurar la replicabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2) RANDOM FOREST\n",
    "X_trRF = pd.read_csv('../data/processed/Split/train/rawsol_X_train.csv', index_col=False).copy()\n",
    "y_trRF = pd.read_csv('../data/processed/Split/train/rawsol_y_train.csv', index_col=False).copy()\n",
    "X_tRF = pd.read_csv('../data/processed/Split/test/rawsol_X_test.csv', index_col=False).copy()\n",
    "y_tRF = pd.read_csv('../data/processed/Split/test/rawsol_y_test.csv', index_col=False).copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,  # Número de árboles en el bosque\n",
    "    max_depth=6,       # Profundidad máxima de cada árbol\n",
    "    random_state=42, #Semilla de orden aleatorio.\n",
    "    min_samples_split=12, #El número mínimo de muestras necesarias para dividir un nodo\n",
    "    min_samples_leaf=4, #El número mínimo de muestras que se deben tener en un nodo hoja en cada árbol\n",
    "    max_features=5, #El número máximo de características a considerar al buscar la mejor división dentro de cada árbol\n",
    ")\n",
    "model = RandomForestClassifier(random_state = 42)\n",
    "model.fit(X_trRF, y_trRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(2, 2, figsize = (20, 15))\n",
    "# Mostramos los 4 primeros árboles de los 100 gen.\n",
    "tree.plot_tree(model.estimators_[0], ax = axis[0, 0], feature_names = list(X_trRF.copy().columns), class_names = [\"0\", \"1\", \"2\"], filled = True)\n",
    "tree.plot_tree(model.estimators_[1], ax = axis[0, 1], feature_names = list(X_trRF.copy().columns), class_names = [\"0\", \"1\", \"2\"], filled = True)\n",
    "tree.plot_tree(model.estimators_[2], ax = axis[1, 0], feature_names = list(X_trRF.copy().columns), class_names = [\"0\", \"1\", \"2\"], filled = True)\n",
    "tree.plot_tree(model.estimators_[3], ax = axis[1, 1], feature_names = list(X_trRF.copy().columns), class_names = [\"0\", \"1\", \"2\"], filled = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predRF = model.predict(X_tRF)\n",
    "y_predRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_tRF, y_predRF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
