{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np, random\n",
                "import pandas as pd\n",
                "import dotenv\n",
                "df_raw = pd.read_csv('C:/Users/Josue/4GA.DataScience/data/raw/Spam.csv')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2999 entries, 0 to 2998\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column   Non-Null Count  Dtype \n",
                        "---  ------   --------------  ----- \n",
                        " 0   url      2999 non-null   object\n",
                        " 1   is_spam  2999 non-null   bool  \n",
                        "dtypes: bool(1), object(1)\n",
                        "memory usage: 26.5+ KB\n",
                        "\n",
                        " --------------------------------------------------------------------------------------- \n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(2999, 2)"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.info()\n",
                "print('\\n','---------------------------------------------------------------------------------------','\\n',)\n",
                "df_raw.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<bound method DataFrame.info of                                                     url  is_spam\n",
                            "0     https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                                https://www.hvper.com/     True\n",
                            "2                    https://briefingday.com/m/v4n3i4f3     True\n",
                            "3      https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                           https://briefingday.com/fan     True\n",
                            "...                                                 ...      ...\n",
                            "2364  https://www.theverge.com/2020/6/29/21306889/di...    False\n",
                            "2365  https://www.smartcitiesworld.net/news/news/dee...    False\n",
                            "2366  https://techcrunch.com/2019/07/04/an-optimisti...    False\n",
                            "2367  https://www.technologyreview.com/2019/12/20/13...    False\n",
                            "2368       https://www.bbc.com/news/technology-51018758    False\n",
                            "\n",
                            "[2369 rows x 2 columns]>"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pasamos un filtro para duplicados, aunque parece que el archivo en cuanto a datos faltantes esta bien!\n",
                "df_raw= df_raw.drop_duplicates()\n",
                "df_raw=df_raw.reset_index(inplace= False, drop = True)\n",
                "df_raw.info\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Entendemos que la segunda columna es la variable target, columna que indica si la primera es spam o no.\n",
                "Como no hay un conjunto para usar y predecir mediante el modelo entrenado creamos el modelo y lo guardamos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#1 Transformamos los datos. La columna descriptiva tendremos que eliminar todo lo que no sean letras. Y sintaxis\n",
                "#De la estructura de un vinculo o enlace web, como wwww/https/.com/es/info... etc\n",
                "#La segunda columna la factorizamos , pasamos el valor binario booleano true , false a 0 o 1.\n",
                "#Si en el paso 1 no lo hacemos correctamente el Modelo SVC 'Técnicamente hablando' tendria fuga de datos\n",
                "#Ya que la estructura de una pagina web es muy reconocible y se facilitaria demasiado al modelo saber si es \n",
                "#Spam"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.microsoft.datawrangler.viewer.v0+json": {
                            "columns": [
                                {
                                    "name": "index",
                                    "rawType": "int64",
                                    "type": "integer"
                                },
                                {
                                    "name": "url",
                                    "rawType": "object",
                                    "type": "string"
                                },
                                {
                                    "name": "is_spam",
                                    "rawType": "int64",
                                    "type": "integer"
                                }
                            ],
                            "conversionMethod": "pd.DataFrame",
                            "ref": "c6eb8b3a-ca8a-4caf-909a-b8778e4209a3",
                            "rows": [
                                [
                                    "0",
                                    "https://briefingday.us8.list-manage.com/unsubscribe",
                                    "1"
                                ],
                                [
                                    "1",
                                    "https://www.hvper.com/",
                                    "1"
                                ],
                                [
                                    "2",
                                    "https://briefingday.com/m/v4n3i4f3",
                                    "1"
                                ],
                                [
                                    "3",
                                    "https://briefingday.com/n/20200618/m#commentform",
                                    "0"
                                ],
                                [
                                    "4",
                                    "https://briefingday.com/fan",
                                    "1"
                                ],
                                [
                                    "5",
                                    "https://www.brookings.edu/interactives/reopening-america-and-the-world/",
                                    "0"
                                ]
                            ],
                            "shape": {
                                "columns": 2,
                                "rows": 6
                            }
                        },
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>https://www.brookings.edu/interactives/reopeni...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...        1\n",
                            "1                             https://www.hvper.com/        1\n",
                            "2                 https://briefingday.com/m/v4n3i4f3        1\n",
                            "3   https://briefingday.com/n/20200618/m#commentform        0\n",
                            "4                        https://briefingday.com/fan        1\n",
                            "5  https://www.brookings.edu/interactives/reopeni...        0"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pasamos la columna Booleana a 1 o 0:\n",
                "df_raw[\"is_spam\"] = df_raw[\"is_spam\"].apply(lambda x: 1 if x else 0).astype(int)\n",
                "df_raw.head(6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                                 url  is_spam\n",
                        "0  [https, briefingday, us, list, manage, com, un...        1\n",
                        "1                           [https, www, hvper, com]        1\n",
                        "2                    [https, briefingday, com, v, i]        1\n",
                        "3          [https, briefingday, com, m, commentform]        0\n",
                        "4                     [https, briefingday, com, fan]        1\n",
                        "5  [https, www, brookings, edu, interactives, reo...        0\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "from urllib.parse import urlparse\n",
                "import pandas as pd\n",
                "\n",
                "def filtrotexto(text):\n",
                "    text = re.sub(r'[^a-z ]', \" \", text.lower())\n",
                "    text = re.sub(r'\\s+[a-z]\\s+', \" \", text)\n",
                "    text = re.sub(r'^[a-z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\s+[a-z]$', \" \", text)\n",
                "    text = re.sub(r'\\s+', \" \", text).strip()\n",
                "    return text.split()\n",
                "\n",
                "def limpiarurl_mejorado(url):\n",
                "    parsed_url = urlparse(url)\n",
                "    cleaned_parts = []\n",
                "\n",
                "    \n",
                "    if parsed_url.scheme:\n",
                "        cleaned_parts.extend(preprocess_url_part(parsed_url.scheme.replace('s', ''))) \n",
                "    if parsed_url.netloc:\n",
                "        netloc_parts = parsed_url.netloc.split('.')\n",
                "        for part in netloc_parts:\n",
                "            sub_parts = part.split('-')\n",
                "            for sub_part in sub_parts:\n",
                "                cleaned_parts.extend(preprocess_url_part(sub_part))    \n",
                "    if parsed_url.path:\n",
                "        path_parts = parsed_url.path.split('/')\n",
                "        for part in path_parts:\n",
                "            cleaned_parts.extend(preprocess_url_part(part))\n",
                "    return [part for part in cleaned_parts if part] # Remove empty strings\n",
                "df_raw[\"url\"] = df_raw[\"url\"].apply(filtrotexto)\n",
                "print(df_raw.head(6))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Puntuaciones de validación cruzada: [0.93924051 0.92405063 0.92141952]\n",
                        "Puntuación media de validación cruzada: 0.9282368858727333\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      1.00      0.98       435\n",
                        "           1       1.00      0.49      0.66        39\n",
                        "\n",
                        "    accuracy                           0.96       474\n",
                        "   macro avg       0.98      0.74      0.82       474\n",
                        "weighted avg       0.96      0.96      0.95       474\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "['C:/Users/Josue/4GA.DataScience/models/vectorizer.joblib']"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import classification_report\n",
                "import joblib\n",
                "import os \n",
                "\n",
                "vectorizer = TfidfVectorizer()\n",
                "X = vectorizer.fit_transform(df_raw['url'].apply(lambda x: ' '.join(x)))\n",
                "y = df_raw['is_spam']\n",
                "model = SVC()\n",
                "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
                "scores = cross_val_score(model, X, y, cv=kf)\n",
                "print(f'Puntuaciones de validación cruzada: {scores}')\n",
                "print(f'Puntuación media de validación cruzada: {scores.mean()}')\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "y_pred = model.predict(X_test)\n",
                "print(classification_report(y_test, y_pred))\n",
                "model_path = os.path.join('models', 'C:/Users/Josue/4GA.DataScience/models/ModelSVC.joblib')\n",
                "vectorizer_path = os.path.join('models', 'C:/Users/Josue/4GA.DataScience/models/vectorizer.joblib')\n",
                "os.makedirs('models', exist_ok=True) \n",
                "joblib.dump(model, model_path)\n",
                "joblib.dump(vectorizer, vectorizer_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DataFrame antes de asignar predicciones:\n",
                        "                          url  is_spam\n",
                        "0               www marca com        2\n",
                        "1   www qdqwdsadqd qqsdsf com        2\n",
                        "2                  www as com        2\n",
                        "3   www qdqwdsadqd qqsdsf com        2\n",
                        "4                www sport es        2\n",
                        "5      www mundodeportivo com        2\n",
                        "6   www qdqwdsadqd qqsdsf com        2\n",
                        "7                www espn com        2\n",
                        "8             http bit ly xyz        2\n",
                        "9           www foxsports com        2\n",
                        "10           http cutt ly abc        2\n",
                        "11  www qdqwdsadqd qqsdsf com        2\n",
                        "12           www cbsports com        2\n",
                        "13       http tinyurl com def        2\n",
                        "14  www qdqwdsadqd qqsdsf com        2\n",
                        "\n",
                        "DataFrame después de asignar predicciones:\n",
                        "                          url  is_spam\n",
                        "0               www marca com        0\n",
                        "1   www qdqwdsadqd qqsdsf com        0\n",
                        "2                  www as com        0\n",
                        "3   www qdqwdsadqd qqsdsf com        0\n",
                        "4                www sport es        0\n",
                        "5      www mundodeportivo com        0\n",
                        "6   www qdqwdsadqd qqsdsf com        0\n",
                        "7                www espn com        0\n",
                        "8             http bit ly xyz        0\n",
                        "9           www foxsports com        0\n",
                        "10           http cutt ly abc        0\n",
                        "11  www qdqwdsadqd qqsdsf com        0\n",
                        "12           www cbsports com        0\n",
                        "13       http tinyurl com def        0\n",
                        "14  www qdqwdsadqd qqsdsf com        0\n",
                        "\n",
                        "Valores únicos en la columna is_spam:\n",
                        "[0]\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "from urllib.parse import urlparse\n",
                "import joblib\n",
                "#En este apartado probaremos el modelo entrenado con un dataframe de prueba con paginas de deportes y paginas inventadasa a mano.\n",
                "# DataFrame de prueba\n",
                "df_test = pd.DataFrame({\n",
                "    'url': [\n",
                "        'www.marca.com',\n",
                "        'www.qdqwdsadqd1224232343419812QQSDSF.com',\n",
                "        'www.as.com',\n",
                "        'www.qdqwdsadqd1224232343419812QQSDSF.com',\n",
                "        'www.sport.es',\n",
                "        'www.mundodeportivo.com',\n",
                "        'www.qdqwdsadqd1224232343419812QQSDSF.com',\n",
                "        'www.espn.com',\n",
                "        'https://bit.ly/xyz123',\n",
                "        'www.foxsports.com',\n",
                "        'https://cutt.ly/abc456',\n",
                "        'www.qdqwdsadqd1224232343419812QQSDSF.com',\n",
                "        'www.cbsports.com',\n",
                "        'https://tinyurl.com/def789',\n",
                "        'www.qdqwdsadqd1224232343419812QQSDSF.com',\n",
                "    ]\n",
                "})\n",
                "df_test['is_spam'] = 2  # Inicializar con 2 para verificar sobrescritura\n",
                "\n",
                "# Funciones de preprocesamiento\n",
                "def filtrotexto(text):\n",
                "    text = re.sub(r'[^a-z ]', \" \", text.lower())\n",
                "    text = re.sub(r'\\s+[a-z]\\s+', \" \", text)\n",
                "    text = re.sub(r'^[a-z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\s+[a-z]$', \" \", text)\n",
                "    text = re.sub(r'\\s+', \" \", text).strip()\n",
                "    return text.split()\n",
                "\n",
                "def preprocess_url_part(part):\n",
                "    return filtrotexto(part)\n",
                "\n",
                "def limpiarurl_mejorado(url):\n",
                "    parsed_url = urlparse(url)\n",
                "    cleaned_parts = []\n",
                "    if parsed_url.scheme:\n",
                "        cleaned_parts.extend(preprocess_url_part(parsed_url.scheme.replace('s', '')))\n",
                "    if parsed_url.netloc:\n",
                "        netloc_parts = parsed_url.netloc.split('.')\n",
                "        for part in netloc_parts:\n",
                "            sub_parts = part.split('-')\n",
                "            for sub_part in sub_parts:\n",
                "                cleaned_parts.extend(preprocess_url_part(sub_part))\n",
                "    if parsed_url.path:\n",
                "        path_parts = parsed_url.path.split('/')\n",
                "        for part in path_parts:\n",
                "            cleaned_parts.extend(preprocess_url_part(part))\n",
                "    return [part for part in cleaned_parts if part]\n",
                "\n",
                "def unir_lista(lista):\n",
                "    return ' '.join(lista)\n",
                "\n",
                "# Preprocesamiento de datos de prueba\n",
                "df_test[\"url\"] = df_test[\"url\"].apply(limpiarurl_mejorado)\n",
                "df_test[\"url\"] = df_test[\"url\"].apply(unir_lista)\n",
                "\n",
                "# Carga de modelo y vectorizador\n",
                "model_path = 'C:/Users/Josue/4GA.DataScience/models/ModelSVC.joblib'\n",
                "vectorizer_path = 'C:/Users/Josue/4GA.DataScience/models/vectorizer.joblib'\n",
                "model = joblib.load(model_path)\n",
                "vectorizer = joblib.load(vectorizer_path)\n",
                "\n",
                "# Vectorización y predicción\n",
                "X_test = vectorizer.transform(df_test['url'])\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Resultados\n",
                "print(\"DataFrame antes de asignar predicciones:\")\n",
                "print(df_test)\n",
                "df_test['is_spam'] = y_pred\n",
                "print(\"\\nDataFrame después de asignar predicciones:\")\n",
                "print(df_test)\n",
                "print(\"\\nValores únicos en la columna is_spam:\")\n",
                "print(df_test['is_spam'].unique())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0rc2"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
